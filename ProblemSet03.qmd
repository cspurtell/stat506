---
title: "Purtell_ProblemSet03"
author: "Colin Purtell"
format:
  html: 
    embed-resources: true
    standalone: true
editor: visual
---

## STATS 506 Problem Set 2:

Link to repository: <https://github.com/cspurtell/stat506>\

### Problem 1

```{r}
library(haven)
library(dplyr)
```

#### a.

```{r}
aux <- read_xpt("data/AUX_I.xpt")
demo <- read_xpt("data/DEMO_I.xpt")

# intersect(names(aux), names(demo))

merged <- inner_join(aux, demo, by = "SEQN")
dim(merged)
```

The merged dataset has 4582 rows and 119 columns

#### b.

For the gender variable:

```{r}
merged <- merged %>%
  mutate(RIAGENDR = case_when(
    RIAGENDR == 1 ~ "Male",
    RIAGENDR == 2 ~ "Female",
    TRUE ~ NA_character_
  )) %>%
  mutate(RIAGENDR = factor(RIAGENDR))
```

For the citizenship status variable:

```{r}
merged <- merged %>%
  mutate(DMDCITZN = case_when(
    DMDCITZN == 1 ~ "Citizen by birth or naturalization",
    DMDCITZN == 2 ~ "Not a citizen",
    DMDCITZN == 7 ~ "Refused",
    DMDCITZN == 9 ~ "Don't Know",
    TRUE ~ NA_character_
  )) %>%
  mutate(DMDCITZN = factor(DMDCITZN))
```

For the number of children variable:

```{r}
merged <- merged %>%
  mutate(
    DMDHHSZA = as.numeric(DMDHHSZA),
    DMDHHSZA = ifelse(DMDHHSZA == 3, 3, DMDHHSZA)
  )
```

For the annual household income variable:

```{r}
merged <- merged %>% 
  mutate(INDHHIN2 = case_when(
    INDHHIN2 == 1  ~ "$0–$4,999",
    INDHHIN2 == 2  ~ "$5,000–$9,999",
    INDHHIN2 == 3  ~ "$10,000–$14,999",
    INDHHIN2 == 4  ~ "$15,000–$19,999",
    INDHHIN2 == 5  ~ "$20,000–$24,999",
    INDHHIN2 == 6  ~ "$25,000–$34,999",
    INDHHIN2 == 7  ~ "$35,000–$44,999",
    INDHHIN2 == 8  ~ "$45,000–$54,999",
    INDHHIN2 == 9  ~ "$55,000–$64,999",
    INDHHIN2 == 10 ~ "$65,000–$74,999",
    INDHHIN2 == 14 ~ "$75,000–$99,999",
    INDHHIN2 == 15 ~ "≥$100,000",
    INDHHIN2 == 12 ~ "$20,000 and over",
    INDHHIN2 == 13 ~ "Under $20,000",
    INDHHIN2 == 77 ~ "Refused",
    INDHHIN2 == 99 ~ "Don't know",
    TRUE ~ NA_character_
  )) %>% 
  mutate(
    INDHHIN2 = factor(
      INDHHIN2,
      levels = c(
        "$0–$4,999", "$5,000–$9,999", "$10,000–$14,999", "$15,000–$19,999",
        "$20,000–$24,999", "$25,000–$34,999", "$35,000–$44,999",
        "$45,000–$54,999", "$55,000–$64,999", "$65,000–$74,999",
        "$75,000–$99,999", "≥$100,000",
        "$20,000 and over", "Under $20,000",
        "Refused", "Don't know"
      )
    )
  )
```

#### c.

Need to convert annual household income to a continuous variable first:

```{r}
income_midpoints <- c(
  `1` = 2500, `2` = 7500, `3` = 12500, `4` = 17500,
  `5` = 22500, `6` = 30000, `7` = 40000, `8` = 50000,
  `9` = 60000, `10` = 70000, `14` = 87500, `15` = 110000,
  `12` = 60000, `13` = 15000, `77` = NA, `99` = NA
)

merged <- merged %>%
  mutate(
    INDHHIN2 = as.numeric(INDHHIN2),
    Income_cont = income_midpoints[as.character(INDHHIN2)]
  )
```

```{r}
library(broom)
library(pscl)
library(knitr)

model_1R <- glm(AUXTWIDR ~ RIAGENDR, data = merged, family = poisson)
model_2R <- glm(AUXTWIDR ~ RIAGENDR + DMDCITZN + DMDHHSZA + INDHHIN2, 
                data = merged, family = poisson)

model_1L <- glm(AUXTWIDL ~ RIAGENDR, data = merged, family = poisson)
model_2L <- glm(AUXTWIDL ~ RIAGENDR + DMDCITZN + DMDHHSZA + INDHHIN2, 
                data = merged, family = poisson)
```

```{r}
summarize_poisson <- function(model) {
  irr <- exp(coef(model))  # incidence rate ratios
  ci <- exp(confint(model))
  
  tidy_df <- broom::tidy(model) %>%
    mutate(
      IRR = exp(estimate),
      CI_low = exp(estimate - 1.96 * std.error),
      CI_high = exp(estimate + 1.96 * std.error)
    ) %>%
    select(term, IRR, CI_low, CI_high, p.value)
  
  stats <- data.frame(
    N = nobs(model),
    Pseudo_R2 = round(pscl::pR2(model)["McFadden"], 3),
    AIC = AIC(model)
  )
  
  list(coefs = tidy_df, stats = stats)
}

m1R <- summarize_poisson(model_1R)
m2R <- summarize_poisson(model_2R)
m1L <- summarize_poisson(model_1L)
m2L <- summarize_poisson(model_2L)
```

The coefficient table is as follows:

```{r}
coefs_table <- bind_rows(
  m1R$coefs %>% mutate(Model = "1R: Right ear (Gender only)"),
  m2R$coefs %>% mutate(Model = "2R: Right ear (Full model)"),
  m1L$coefs %>% mutate(Model = "1L: Left ear (Gender only)"),
  m2L$coefs %>% mutate(Model = "2L: Left ear (Full model)")
) %>%
  select(Model, term, IRR, CI_low, CI_high, p.value) %>%
  mutate(across(c(IRR, CI_low, CI_high, p.value), ~round(., 3)))

kable(coefs_table, caption = "Incidence Rate Ratios for Poisson Models")
```

The model statistics table is as follows:

```{r}
stats_table <- bind_rows(
  m1R$stats %>% mutate(Model = "1R: Right ear (Gender only)"),
  m2R$stats %>% mutate(Model = "2R: Right ear (Full model)"),
  m1L$stats %>% mutate(Model = "1L: Left ear (Gender only)"),
  m2L$stats %>% mutate(Model = "2L: Left ear (Full model)")
) %>%
  select(Model, N, Pseudo_R2, AIC)

kable(stats_table, caption = "Model Sample Sizes, Pseudo-R², and AIC Values")
```

#### d.

```{r}
summary(model_2L)
```

In Model 2L, there is a small but statistically significant gender difference in tympanometric width of the left ear (IRR = 0.988, p \< 0.001). This suggests that, holding citizenship, number of young children, and income constant, males have on average slightly lower tympanometric width than females.

```{r}
exp(coef(model_2L))   # IRRs
```

Specifically, we find that males have a 1.2% lower expected rate of the outcome, holding all else constant. This is because the IRR is less than 1.

### Problem 2

```{r}
library(DBI)
library(RSQLite)
library(microbenchmark)

con <- dbConnect(RSQLite::SQLite(), "data/sakila_master.db")
# dbListTables(con)
```

#### a.

Using R operations:

```{r}
customer_df <- dbGetQuery(con, "SELECT customer_id, store_id, active FROM customer") %>% 
  mutate(active = as.numeric(active))
store_df <- dbGetQuery(con, "SELECT store_id, address_id FROM store")
store_stats <- customer_df %>%
  group_by(store_id) %>%
  summarise(
    total_customers = n(),
    active_customers = sum(active),
    pct_active = round(100 * active_customers / total_customers, 2)
  )
store_stats
```

Using a single SQL query:

```{r}
query <- "
SELECT 
  store_id,
  COUNT(customer_id) AS total_customers,
  SUM(active) AS active_customers,
  ROUND(100.0 * SUM(active)/COUNT(customer_id), 2) AS pct_active
FROM customer
GROUP BY store_id
"

store_stats_sql <- dbGetQuery(con, query)
store_stats_sql
```

Testing performance of the above methods:

```{r}
microbenchmark(
  R_approach = {
    customer_df %>%
      group_by(store_id) %>%
      summarise(total_customers = n(),
                active_customers = sum(active),
                pct_active = round(100 * active_customers / n(), 2))
  },
  SQL_approach = dbGetQuery(con, query),
  times = 10
)
```

#### b.

Using R operations:

```{r}
staff_df <- dbGetQuery(con, "SELECT staff_id, first_name, last_name, address_id FROM staff")
address_df <- dbGetQuery(con, "SELECT address_id, city_id FROM address")
city_df <- dbGetQuery(con, "SELECT city_id, country_id FROM city")
country_df <- dbGetQuery(con, "SELECT country_id, country FROM country")

staff_country <- staff_df %>%
  left_join(address_df, by = "address_id") %>%
  left_join(city_df, by = "city_id") %>%
  left_join(country_df, by = "country_id") %>%
  select(first_name, last_name, country)
staff_country
```

Using a single SQL query:

```{r}
query <- "
SELECT s.first_name, s.last_name, c.country
FROM staff s
JOIN address a ON s.address_id = a.address_id
JOIN city ci ON a.city_id = ci.city_id
JOIN country c ON ci.country_id = c.country_id
"

staff_country_sql <- dbGetQuery(con, query)
staff_country_sql
```

Testing performance of the above methods:

```{r}
microbenchmark(
  R_approach = {
    staff_df %>%
      left_join(address_df, by = "address_id") %>%
      left_join(city_df, by = "city_id") %>%
      left_join(country_df, by = "country_id") %>%
      select(first_name, last_name, country)
  },
  SQL_approach = dbGetQuery(con, query),
  times = 10
)
```

#### c.

Using R operations:

```{r}
payment_df <- dbGetQuery(con, "SELECT rental_id, amount FROM payment")
rental_df <- dbGetQuery(con, "SELECT rental_id, inventory_id FROM rental")
inventory_df <- dbGetQuery(con, "SELECT inventory_id, film_id FROM inventory")
film_df <- dbGetQuery(con, "SELECT film_id, title FROM film")

film_value <- payment_df %>%
  left_join(rental_df, by = "rental_id") %>%
  left_join(inventory_df, by = "inventory_id") %>%
  left_join(film_df, by = "film_id") %>%
  group_by(film_id, title) %>%
  summarise(total_value = sum(amount), .groups = 'drop')
film_value %>% filter(total_value == max(total_value))
```

Using a single SQL query:

```{r}
query <- "
SELECT f.title, SUM(p.amount) AS total_value
FROM payment p
JOIN rental r ON p.rental_id = r.rental_id
JOIN inventory i ON r.inventory_id = i.inventory_id
JOIN film f ON i.film_id = f.film_id
GROUP BY f.film_id, f.title
HAVING SUM(p.amount) = (
    SELECT MAX(total_val) FROM (
        SELECT SUM(p2.amount) AS total_val
        FROM payment p2
        JOIN rental r2 ON p2.rental_id = r2.rental_id
        JOIN inventory i2 ON r2.inventory_id = i2.inventory_id
        GROUP BY i2.film_id
    )
)
"

film_max_sql <- dbGetQuery(con, query)
film_max_sql
```

Testing the performance of the above methods:

```{r}
microbenchmark(
  R_approach = {
    film_value <- payment_df %>%
      left_join(rental_df, by = "rental_id") %>%
      left_join(inventory_df, by = "inventory_id") %>%
      left_join(film_df, by = "film_id") %>%
      group_by(film_id, title) %>%
      summarise(total_value = sum(amount), .groups='drop')
    film_value %>% filter(total_value == max(total_value))
  },
  SQL_approach = dbGetQuery(con, query),
  times = 10
)
```

### Problem 3

```{r}
aus_data <- read.csv("data/au-500.csv")
```

#### a.

```{r}
library(stringr)
percent_com <- mean(str_detect(aus_data$web, "\\.com$")) * 100
percent_com
```

There does not appear to be any website URLS ending in .com, as they all seem to end in .com.aus

#### b.

```{r}
domains <- str_extract(aus_data$email, "(?<=@).*")
most_common_domain <- domains %>% table() %>% sort(decreasing = TRUE)
most_common_domain[1]
```

The most common domain name appears to be hotmail.com

#### c.

```{r}
non_alpha <- str_detect(aus_data$company_name, "[^A-Za-z ,]")
prop_non_alpha <- mean(non_alpha)
prop_non_alpha
```

Approximately 9% of company names contain non-alphabetic characters

```{r}
non_alpha2 <- str_detect(aus_data$company_name, "[^A-Za-z ,&]")
prop_non_alpha2 <- mean(non_alpha2)
prop_non_alpha2
```

Excluding ampersands, this proportion decreases to 8%

#### d.

```{r}
convert_to_cell <- function(phone) {
  phone <- gsub("-", "", phone)
  ifelse(str_length(phone) == 10,
         paste0(substr(phone,1,4), "-", substr(phone,5,7), "-", substr(phone,8,10)),
         phone)
}

aus_data$phone1 <- sapply(aus_data$phone1, convert_to_cell)
aus_data$phone2 <- sapply(aus_data$phone2, convert_to_cell)
head(aus_data$phone1, 10)
head(aus_data$phone2, 10)
```

#### e.

```{r}
library(ggplot2)
apt_num <- as.numeric(str_extract(aus_data$address, "(?<=#)\\d+"))
ggplot(data.frame(apt_num), aes(x=log(apt_num))) +
  geom_histogram(binwidth = 0.5, fill="blue", color="black") +
  labs(title="Histogram of log(Apartment Numbers)", x="log(Apartment Number)", y="Count")
```

#### f.

```{r}
leading_digit <- as.numeric(substr(apt_num, 1, 1))
benford_table <- table(leading_digit)/length(leading_digit)
benford_expected <- log10(1 + 1/1:9)

data.frame(Digit = 1:9, Observed = benford_table, Expected = benford_expected)
```

According to the above table, every leading digit has the same observed frequency in the fake data. This differs greatly from the expected distribution from Benford's Law, as seen in the far-right column. Therefore, it is doubtful that the apartment numbers would pass as real data.

#### Resources Used

Tidyverse documentation for str_detect(), other stringr functions, and assistance with Problem 2, R documentation for glm() function, ChatGPT for debugging and explanation of implementation of Benford's Law.
